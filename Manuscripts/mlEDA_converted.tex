% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{article}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage[margin=1in]{geometry}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=true,citecolor=blue,linkcolor=blue}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric,arrows}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={mlEDA: an interactive tool for guided standardized exploratory analysis workflow of multivariate longitudinal data},
  pdfauthor={Ying Jin; Shanshan Zhao; David Umbach; Mandy Goldberg},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{mlEDA: an interactive tool for guided standardized exploratory
analysis workflow of multivariate longitudinal data}
\author{Ying Jin \and Shanshan Zhao \and David Umbach \and Mandy
Goldberg}
\date{2026-02-10}

\begin{document}
\maketitle

\maketitle

\section{Introduction}\label{introduction}

\label{sec:intro}

\subsection{Motivation}\label{motivation}

\label{sec:intro1}

Measures of health are often routinely collected over time in both
research and clinical settings. For exmaple, individuals are likely to
go through the same set of procedures during annual physical exams, such
as vitals and blood/urine tests. The health indicators collected during
these procedures are closely monitored for preventive health and can
also be important basis for personalized health. In laboratory
environment, multiple biomarkers maybe followed over time to understand
the evolution of biological pathways. In community settings, large-scale
surveys and censuses are conducted regularly to collect environmental,
lifestyle, and socioeconomic information as basis of community health
improvement. All of the above examples involve the collection of
multiple measures temporally, namely the
\textit{multivariate temporal data}. Because of the scale and complexity
of such information, exploratory analysis is necessary. Investigators
need effective and comprehensive representation of the data structure,
so that potential problem can be identified, which further facilitates
hypothesis generation and resource allocation for further research work.

For a multivariate dataset collected over time, the correlation between
the collected measures, especially how the correlation changes
temporally, often reveal vital information. For example, changes in
correlation between Earth system variables can provide valuable
information for the assessment of the climate engineering deployment
scenarios(\citeproc{ref-Mengis2019climate}{Mengis et al. 2019}). An
effective exploration of the evolving structure of variables is an
essential step of Exploratory Data Analysis (EDA) that will have
fundamental impact on the following analysis, including hypothesis
generating, model selection and scientific discoveries. Unfortunately,
exploratory analysis methods and tools for multivariate temporal
datasets are not well-developed, especially on the analysis of
correlation. While exploration of data largely depend on graphic
visualization, making such graphs demands high technical skills
(e.g.~programming, usage of specific software). As a result, domain
experts without easy access to these techniques, are often discouraged
from these tools that could significantly improve analysis efficiency.
In interdisciplinary collaborations and/or public communication, these
technicalities often cause communication barriers. The lack of
intuitive, interpretable representation of information causes difficult
in comprehension, and as a consequence discourages collaborators and
audience from raising questions and feedback. Moreover, existing
exploratory analysis are perceived as isolated summary tables and
graphs, instead of a complete workflow. Different visualization schemes
or summary statistics that can reflect different aspects of the same
dataset are presented separately for the sole purpose of supporting more
advanced analysis, and are rarely cross-reference. There also lacks a
standardize EDA workflow, leaving the choice of methods largely up to
discretion. The partiality and inconsistency does not help investigator
to view the evidence integrally or objectively.

The challenge above has inspired the development of TempNet-an
accessible toolkit with a interactive, standardized workflow for
exploratory analysis of multivariate temporal data. It comprehensively
presents various aspects of data structure, visualizes the
time-dependent intercorrelation, and is easy to operate even for users
without statistical or coding background.

\subsection{Previous work}\label{previous-work}

\label{sec:intro2} \% exisiting tools for multivariate temporal data
EDA: \% pairwise

The structure of multivariate temporal datasets prohibits both
mutli-dimensionality and temporal evolution. However, existing EDA
methods are largely based on single variable or pairwise examination.
Summary statistics (e.g., mean, standard deviation) and plots
(e.g.~boxplots, histograms) can summarize the distribution of variables
one by one and time point by time point. The association between
variables is often presented by pairwise matrix-based representation,
such as correlation matrix, scatterplot matrix or heatmaps. These
methods work well on small- or medium-dimensional datasets. However, the
increasing dimensionality rapidly expands the information to summarize.
The naive method above quickly become infeasible, because the density of
information becomes too overwhelming for human eyes. In addition, these
tools are also static and cannot reflect temporal changes. With the
extra complexity of temporal evolution, they have to be reproduced at
every time point. Investigators are required to flip back and forth
across slices for examination and comparison. Such operation is not a
good fit for information processing in human brain, as its
time-consuming and repetitive, which increase the likelihood or error or
negligence.

Current literature has proposed methods for the visualization of
high-dimensional or large-scale data. Since the challenge essential
stems from scale, it is natural to use dimension reduction techniques.
When the goal of analysis is to explore variable relationships, the
subject of analysis becomes the correlation matrix instead of the data
itself. Intuitively, one can also think of the correlation matrix as a
dataset where each variable (row) is a subject, and its features are its
correlation with other variables (columns). In this case, the
correlation matrix essential becomes a time-dependent dataset with
sample size equal to number of features. This naturally leads to the
consideration of dimension reduction methods. However, one should be
alert that this data violates the assumptions of many dimension
reduction techniques designed for regular data matrices, render these
methods inapplicable. For example, the rows (variables) are unlikely to
be independently distributed like subjects. Moreover, the samples used
to calculate correlation are not necessary the same across time, which
is a very common case for regular large-scale population-level surveys
like the NHANES data(\citeproc{ref-NHANES}{Centers for Disease Control
and Prevention and National Center for Health Statistics 2025}). These
studies consistently collect the same measure, but participants who took
the survey change every time. With correlated variables and inconsistent
sample, the correlation matrices, though time-dependent and even with
the same set of variables, cannot be classified as ``longitudinal''
dataset. This makes many EDA methods based on longitudinal model
inapplicable, such as Group-Based Model Trajectory (GBMT) and Latent
Class Mixed Effect Model(\citeproc{ref-Lu2024LongCluster}{Lu, n.d.}). To
decompose such a dataset, we need a dimension reduction method that
imposes little assumptions on the data. One such example is
Multidimensional Scaling (MDS) (also known as Principal Coordinates
Analysis(\citeproc{ref-gower1966pcoa}{Gower 1966}). It represents a
high-dimensional datasets on a lower-dimensional space, similar to
Principal Component Analysis (PCA), but with less rigorous restrictions.
MDS does not require linearity nor approximate Gaussian distribution. It
is also designed to preserve the high-dimensional structure as much as
possible, which PCA is not necessarily able to achieve. Considering the
purpose of EDA is to examine the correlation matrix, it is ideal to
preserve its structure, making MDS a better reduction for this specific
case.

The R package \textit{corrr} uses this method visualize a correlation
matrices(\citeproc{ref-corrr}{Kuhn, Jackson, and Cimentada 2022}). The
MDS process is embedded into the \textit{network\_plot} function. The
correlation matrix is represented on a 2D space in a network plot
format, where each variable is represented by a node and their
coordinates is the output of MDS algorithms. The original value of
correlation is also plotted as the edge between nodes, where the
magnitude and sign of correlation coefficient are reflected in the
thickness, transparency and color of edges. This function offers a
clean, comprehensive visualization where variable correlation can be
intuitively perceived by their relative positioning-the stronger the
correlation is, the closer the variables are positioned to each other.
However, it is a static plot and thus is subject to the same repetition
procedure mentioned above when visualizing temporal evolution.

Other R packages, although not explicitly for correlation, have been
developed to combine MDS reduction with network visualization, such as
\textit{igraph}(\citeproc{ref-igraph}{Csardi and Nepusz 2005}). One can
also implement the two steps separately-generate coordinates with MDS
first and then plot variables in a network. R built-in function
\textit{cmdscale}(\citeproc{ref-Rbuildin}{R Core Team 2025}), packages
\textit{MASS}(\citeproc{ref-MASS}{Venables and Ripley 2002}) and
\textit{smacof}(\citeproc{ref-smacof}{Mair, Groenen, and de Leeuw 2022})
are good tools for implementing MDS and its many variations. Then we
could make network plots with packages like
\textit{igraph}(\citeproc{ref-igraph}{Csardi and Nepusz 2005}) and
\textit{ggplot}(\citeproc{ref-ggplot2}{Wickham 2016}). However, these
packages also have limitations in representing temporal evolution-they
can only represent one time point at a time. Integration over time
requires additional tool to combine slices into graphic interchange
format or animation. There have been a few packages developed for
interactive or dynamic visualization, such as
\textit{ndtv}(\citeproc{ref-ndtv}{Bender-deMoll 2024}) and
\textit{networkDynamic}(\citeproc{ref-networkDynamic}{Butts et al.
2024}). These packages do not require repetition of the entire process,
but the data has to be formatted carefully such that time-varying
features are explicitly specified for each time point. All the packages
mentioned require high technical ability, such as fluency in R
programming and understanding of data structure. They are not friendly
to users without much technical background or coding experience, such as
domain scientists or public user.

Another shortcoming of existing EDA tools is their lack of coherence and
interactivity. Each analysis methods are often implemented in isolation,
producing single figure or summary statistics reflecting only a small
component of the entire dataset. In practice, we often desire an
integrated view of the entire dataset, especially with multiple
variables across multiple time. Cross-reference across different
components of data is frequently needed but not sufficiently supported
by the existing exploratory analysis scheme. A more fluid, interactive
workflow could release these operation burdens and thus improve
efficiency of analysis. It can also overcome interdisciplinary
communication barrier when accompanied with intuitive representation.
Existing literature has demonstrated the preference toward interactive
tools (\citeproc{ref-Lakkaraju2022}{Lakkaraju et al. 2022}).
Unfortunately, development in this areas has been sparse, with existing
work largely restricted to non-exploratory modeling or univariate and
bivariate summary (\citeproc{ref-EpiStatKit}{Saxena, n.d.}), or
generative AI applications based on black-box deep learning.

\% MEEW: \url{https://peischllab.github.io/MEEW.html} \% for teaching
students applied mathematical modelling in ecology and evolution

\% EpiStatKit: \url{https://epistatkit.vercel.app/} \% Epidemiology
modeling

In a nutshell, the existing tools for temporal network visualization
require users to be efficient in data analysis and programming. Many of
these tools are not designed for data exploratory analysis or only naive
exploration, and lack interactivity of intuitive representation. For
domain experts without statistical background or coding experiences,
they are not accessible and the learning curve can be sharp.

\printbibliography

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-ndtv}
Bender-deMoll, Skye. 2024. \emph{Ndtv: Network Dynamic Temporal
Visualizations}. \url{https://doi.org/10.32614/CRAN.package.ndtv}.

\bibitem[\citeproctext]{ref-networkDynamic}
Butts, Carter T., Ayn Leslie-Cook, Pavel N. Krivitsky, and Skye
Bender-deMoll. 2024. \emph{networkDynamic: Dynamic Extensions for
Network Objects}.
\url{https://doi.org/10.32614/CRAN.package.networkDynamic}.

\bibitem[\citeproctext]{ref-NHANES}
Centers for Disease Control and Prevention, and National Center for
Health Statistics. 2025. {``{National Health and Nutrition Examination
Survey Data}.''} Hyattsville, MD:
\url{https://www.cdc.gov/nchs/nhanes/index.htm}; U.S. Department of
Health; Human Services.

\bibitem[\citeproctext]{ref-igraph}
Csardi, Gabor, and Tamas Nepusz. 2005. {``The Igraph Software Package
for Complex Network Research.''} \emph{InterJournal} Complex Systems
(November): 1695.

\bibitem[\citeproctext]{ref-gower1966pcoa}
Gower, J. C. 1966. {``Some Distance Properties of Latent Root and Vector
Methods Used in Multivariate Analysis.''} \emph{Biometrika} 53 (3/4):
325--38. \url{http://www.jstor.org/stable/2333639}.

\bibitem[\citeproctext]{ref-corrr}
Kuhn, Max, Simon Jackson, and Jorge Cimentada. 2022. \emph{Corrr:
Correlations in r}. \url{https://doi.org/10.32614/CRAN.package.corrr}.

\bibitem[\citeproctext]{ref-Lakkaraju2022}
Lakkaraju, Himabindu, Dylan Slack, Yuxin Chen, Chenhao Tan, and Sameer
Singh. 2022. {``Rethinking Explainability as a Dialogue: A
Practitioner's Perspective.''} \emph{NeurIPS Workshop on Human Centered
AI}. \url{https://par.nsf.gov/biblio/10462932}.

\bibitem[\citeproctext]{ref-Lu2024LongCluster}
Lu, Zihang. n.d. {``Clustering Longitudinal Data: A Review of Methods
and Software Packages.''} \emph{International Statistical Review} n/a
(n/a). https://doi.org/\url{https://doi.org/10.1111/insr.12588}.

\bibitem[\citeproctext]{ref-smacof}
Mair, Patrick, Patrick Groenen, and Jan de Leeuw. 2022.
{``Multidimensional Scaling Using Majorization: SMACOF in r.''}
\emph{Journal of Statistical Software} 102.
\url{https://doi.org/10.18637/jss.v102.i10}.

\bibitem[\citeproctext]{ref-Mengis2019climate}
Mengis, Nadine, Dennis P. Keller, Wilfried Rickels, and et al. 2019.
{``Climate Engineering--Induced Changes in Correlations Between Earth
System Variables--Implications for Appropriate Indicator Selection.''}
\emph{Climatic Change} 153: 305--22.
\url{https://doi.org/10.1007/s10584-019-02389-7}.

\bibitem[\citeproctext]{ref-Rbuildin}
R Core Team. 2025. \emph{R: A Language and Environment for Statistical
Computing}. Vienna, Austria: R Foundation for Statistical Computing.
\url{https://www.R-project.org/}.

\bibitem[\citeproctext]{ref-EpiStatKit}
Saxena, Pulkit. n.d. {``Advanced Biostatistics and Epidemiology Toolkit
for Clinical Monitoring and Research.''}
\url{https://epistatkit.vercel.app/}.

\bibitem[\citeproctext]{ref-MASS}
Venables, W. N., and B. D. Ripley. 2002. \emph{Modern Applied Statistics
with s}. Fourth. New York: Springer.
\url{https://www.stats.ox.ac.uk/pub/MASS4/}.

\bibitem[\citeproctext]{ref-ggplot2}
Wickham, Hadley. 2016. \emph{Ggplot2: Elegant Graphics for Data
Analysis}. Springer-Verlag New York.
\url{https://ggplot2.tidyverse.org}.

\end{CSLReferences}

\end{document}
