---
title: "mlEDA: an interactive tool for guided standardized exploratory analysis workflow of multivariate longitudinal data"
author:
  - Ying Jin
  - Shanshan Zhao
  - David Umbach
  - Mandy Goldberg
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
bibliography: refs.bib
link-citations: true
header-includes:
  - \usepackage[margin=1in]{geometry}
  - \usepackage{subcaption}
  - \usepackage{booktabs}
  - \usepackage{amsmath}
  - \usepackage{bm}
  - \usepackage{xcolor}
  - \usepackage{hyperref}
  - \hypersetup{colorlinks=true,citecolor=blue,linkcolor=blue}
  - \usepackage{tikz}
  - \usetikzlibrary{shapes.geometric,arrows}
---



\maketitle

<!-- % switch temporal to longitudinal -->
<!-- % App name: mlEDA (back up: mTEDA, mRMEDA) -->

# Introduction
\label{sec:intro}

## Motivation
\label{sec:intro1}

Measures of health are often routinely collected over time in both research and clinical settings. For exmaple, individuals are likely to go through the same set of procedures during annual physical exams, such as vitals and blood/urine tests. The health indicators collected during these procedures are closely monitored for preventive health and can also be important basis for personalized health. In laboratory environment, multiple biomarkers maybe followed over time to understand the evolution of biological pathways. In community settings, large-scale surveys and censuses are conducted regularly to collect environmental, lifestyle, and socioeconomic information as basis of community health improvement. All of the above examples involve the collection of multiple measures temporally, namely the \textit{multivariate temporal data}. Because of the scale and complexity of such information, exploratory analysis is necessary. Investigators need effective and comprehensive representation of the data structure, so that potential problem can be identified, which further facilitates hypothesis generation and resource allocation for further research work. 

For a multivariate dataset collected over time, the correlation between the collected measures, especially how the correlation changes temporally, often reveal vital information. For example, changes in correlation between Earth system variables can provide valuable information for the assessment of the climate engineering deployment scenarios[@Mengis2019climate]. An effective exploration of the evolving structure of variables is an essential step of Exploratory Data Analysis (EDA) that will have fundamental impact on the following analysis, including hypothesis generating, model selection and scientific discoveries. Unfortunately, exploratory analysis methods and tools for multivariate temporal datasets are not well-developed, especially on the analysis of correlation. While exploration of data largely depend on graphic visualization, making such graphs demands high technical skills (e.g. programming, usage of specific software). As a result, domain experts without easy access to these techniques, are often discouraged from these tools that could significantly improve analysis efficiency. In interdisciplinary collaborations and/or public communication, these technicalities often cause communication barriers. The lack of intuitive, interpretable representation of information causes difficult in comprehension, and as a consequence discourages collaborators and audience from raising questions and feedback. Moreover, existing exploratory analysis are perceived as isolated summary tables and graphs, instead of a complete workflow. Different visualization schemes or summary statistics that can reflect different aspects of the same dataset are presented separately for the sole purpose of supporting more advanced analysis, and are rarely cross-reference. There also lacks a standardize EDA workflow, leaving the choice of methods largely up to discretion. The partiality and inconsistency does not help investigator to view the evidence integrally or objectively. 

The challenge above has inspired the development of TempNet-an accessible toolkit with a interactive, standardized workflow for exploratory analysis of multivariate temporal data. It comprehensively presents various aspects of data structure, visualizes the time-dependent intercorrelation, and is easy to operate even for users without statistical or coding background.



## Previous work
\label{sec:intro2}


The structure of multivariate temporal datasets prohibits both mutli-dimensionality and temporal evolution. However, existing EDA methods are largely based on single variable or pairwise examination. Summary statistics (e.g., mean, standard deviation) and plots (e.g. boxplots, histograms) can summarize the distribution of variables one by one and time point by time point. The association between variables is often presented by pairwise matrix-based representation, such as correlation matrix, scatterplot matrix or heatmaps. These methods work well on small- or medium-dimensional datasets. However, the increasing dimensionality rapidly expands the information to summarize. The naive method above quickly become infeasible, because the density of information becomes too overwhelming for human eyes. In addition, these tools are also static and cannot reflect temporal changes. With the extra complexity of temporal evolution, they have to be reproduced at every time point. Investigators are required to flip back and forth across slices for examination and comparison. Such operation is not a good fit for information processing in human brain, as its time-consuming and repetitive, which increase the likelihood or error or negligence. 

Current literature has proposed methods for the visualization of high-dimensional or large-scale data. Since the challenge essential stems from scale, it is natural to use dimension reduction techniques. When the goal of analysis is to explore variable relationships, the subject of analysis becomes the correlation matrix instead of the data itself. Intuitively, one can also think of the correlation matrix as a dataset where each variable (row) is a subject, and its features are its correlation with other variables (columns). In this case, the correlation matrix essential becomes a time-dependent dataset with sample size equal to number of features. This naturally leads to the consideration of dimension reduction methods. However, one should be alert that this data violates the assumptions of many dimension reduction techniques designed for regular data matrices, render these methods inapplicable. For example, the rows (variables) are unlikely to be independently distributed like subjects. Moreover, the samples used to calculate correlation are not necessary the same across time, which is a very common case for regular large-scale population-level surveys like the NHANES data[@NHANES]. These studies consistently collect the same measure, but participants who took the survey change every time. With correlated variables and inconsistent sample, the correlation matrices, though time-dependent and even with the same set of variables, cannot be classified as "longitudinal" dataset. This makes many EDA methods based on longitudinal model inapplicable, such as Group-Based Model Trajectory (GBMT) and Latent Class Mixed Effect Model[@Lu2024LongCluster]. To decompose such a dataset, we need a dimension reduction method that imposes little assumptions on the data. One such example is Multidimensional Scaling (MDS) (also known as Principal Coordinates Analysis[@gower1966pcoa]. It represents a high-dimensional datasets on a lower-dimensional space, similar to Principal Component Analysis (PCA), but with less rigorous restrictions. MDS does not require linearity nor approximate Gaussian distribution. It is also designed to preserve the high-dimensional structure as much as possible, which PCA is not necessarily able to achieve. Considering the purpose of EDA is to examine the correlation matrix, it is ideal to preserve its structure, making MDS a better reduction for this specific case. 

The R package \textit{corrr} uses this method visualize a correlation matrices[@corrr]. The MDS process is embedded into the \textit{network\_plot} function. The correlation matrix is represented on a 2D space in a network plot format, where each variable is represented by a node and their coordinates is the output of MDS algorithms. The original value of correlation is also plotted as the edge between nodes, where the magnitude and sign of correlation coefficient are reflected in the thickness, transparency and color of edges. This function offers a clean, comprehensive visualization where variable correlation can be intuitively perceived by their relative positioning-the stronger the correlation is, the closer the variables are positioned to each other. However, it is a static plot and thus is subject to the same repetition procedure mentioned above when visualizing temporal evolution. 

Other R packages, although not explicitly for correlation, have been developed to combine MDS reduction with network visualization, such as \textit{igraph}[@igraph]. One can also implement the two steps separately-generate coordinates with MDS first and then plot variables in a network. R built-in function \textit{cmdscale}[@Rbuildin], packages \textit{MASS}[@MASS] and \textit{smacof}[@smacof] are good tools for implementing MDS and its many variations. Then we could make network plots with packages like \textit{igraph}[@igraph] and \textit{ggplot}[@ggplot2]. However, these packages also have limitations in representing temporal evolution-they can only represent one time point at a time. Integration over time requires additional tool to combine slices into graphic interchange format or animation. There have been a few packages developed for interactive or dynamic visualization, such as \textit{ndtv}[@ndtv] and \textit{networkDynamic}[@networkDynamic]. These packages do not require repetition of the entire process, but the data has to be formatted carefully such that time-varying features are explicitly specified for each time point. All the packages mentioned require high technical ability, such as fluency in R programming and understanding of data structure. They are not friendly to users without much technical background or coding experience, such as domain scientists or public user. 

Another shortcoming of existing EDA tools is their lack of coherence and interactivity. Each analysis methods are often implemented in isolation, producing single figure or summary statistics reflecting only a small component of the entire dataset. In practice, we often desire an integrated view of the entire dataset, especially with multiple variables across multiple time. Cross-reference across different components of data is frequently needed but not sufficiently supported by the existing exploratory analysis scheme. A more fluid, interactive workflow could release these operation burdens and thus improve efficiency of analysis. It can also overcome interdisciplinary communication barrier when accompanied with intuitive representation. Existing literature has demonstrated the preference toward interactive tools [@Lakkaraju2022]. Unfortunately, development in this areas has been sparse, with existing work largely restricted to non-exploratory modeling or univariate and bivariate summary [@EpiStatKit], or generative AI applications based on black-box deep learning. 

% MEEW: https://peischllab.github.io/MEEW.html
%   for teaching students applied mathematical modelling in ecology and evolution

% EpiStatKit: https://epistatkit.vercel.app/
%   Epidemiology modeling

In a nutshell, the existing tools for temporal network visualization require users to be efficient in data analysis and programming. Many of these tools are not designed for data exploratory analysis or only naive exploration, and lack interactivity of intuitive representation. For domain experts without statistical background or coding experiences, they are not accessible and the learning curve can be sharp. 

<!-- # The TempNet App -->
<!-- \label{set:app} -->

<!-- % potential names: Tnet, TemporalNet, TempoNet -->
<!-- To address the challenges in Section \ref{sec:intro}, we have created TempNet, a web-based application designed for interactive, standardized exploratory analysis workflow of multivariate temporal dataset. This application is an integration of classical EDA components and novel multidimensional visualization scheme. It also has the ability to visualize temporal evolution dynamically and intuitively to human vision. Moreover, it guides users through an comprehensive analytical workflow with interactive operations. Its usage requires minimal technical background or coding experience, thus desirable for the interdisciplinary collaboration settings. This section will demonstrate the functionalities of TempNet in details, using the the Infant Feeding and Early Development (IFED) study [@Adgent2018IFED] as a motivational example. The same dataset will also serve as a case study example in Section \ref{sec:case}.  -->

<!-- ## Motivational dataset -->

<!-- The Infant Feeding and Early Development (IFED) study [@Adgent2018IFED] is an NIH-funded longitudinal observational study of infant development after birth. Although it recruited both boys and girls, different biological sexes are often analyzed separately due to the essential difference in early development process. For this paper, we use the subset of 136 girls followed from birth to 36 weeks. The participants are followed up through routine clinical visits every 2-4 weeks. In each visit, the participants went through one or more of the following procedures: 1) physical examination; 2) specimen collection; and 3) ultrasounds. Each procedures collected multiple measures. Physical examination collected basic growth information such as height, weight, head circumference, as well as manually measured reproductive development, such as anogenital and bud bead size. Blood specimen collected hormones measures including FSH, estradiol and testosterone. Ultrasound collected organ size, including thyroid, uterus, ovary and bud bead.  -->

<!-- The IFED data is a typical example of the multivariate temporal data structure, where multiple variables are repeatedly collected over time. -->
<!-- Although the repeated measures can be collected from the same individual, the timing of collection procedures are not aligned, and at each visit there are significant proportion of missing values. Therefore, the actual effective sample changes across time and at each visit. The physical exam is the most consistent procedure, implemented at every scheduled visit with small number of missing values. Ultrasound, on the other hand, is scheduled every other visit, with over 50\% missing values at most scheduled visits. Depending on how the time variable is coded, the inconsistency can impose challenge to data exploration. For example, when the "time" information is coded as "age in days after birth", mostly time points have only a few observations, causing correlation or association measures at this specific time points unreliable. If there are only two complete pairs between two variables, the correlation will always be 1, which is clearly not an accurate representation.  -->





<!-- ## Functionalities -->
<!-- \label{sec:appfunc} -->

<!-- % consolidate figures into one figure with sub figures -->

<!-- % A quick tour of functions and work flow, with a flow chart. -->
<!-- \begin{figure} -->
<!--     \centering -->
<!-- \begin{tikzpicture} -->
<!--     % major nodes -->
<!--     \node(tab1)[io]{Data upload \& preview}; -->
<!--     \node(tab2)[io, right of = tab1, xshift=3cm]{Descripitives}; -->
<!--     \node(tab3)[io, right of = tab2, xshift=3cm]{Temporal Visualization}; -->
<!--     \node(tab4)[io, right of = tab3, xshift=3cm]{Integrated Visualization}; -->
<!--     % arrows -->
<!--     \draw[arrow](tab1)--(tab2); -->
<!--     \draw[arrow](tab2)--(tab3); -->
<!--     \draw[arrow](tab3)--(tab4); -->
<!--     % minor nodes: tab2 -->
<!--     \node(tab2_1)[process, below of = tab2, yshift = -0.3cm]{Univariate}; -->
<!--     \node(tab2_2)[process, below of = tab2_1, yshift = -0.3cm]{Pariwise}; -->
<!--     \node(tab2_3)[process, below of = tab2_2, yshift = -0.3cm]{Overall}; -->
<!--     % minor modes: tab 3 -->
<!--     \node(tab3_1)[process, below of = tab3, yshift=-0.5cm]{Correlation network}; -->
<!--     \node(tab3_2)[process, below of = tab3_1, yshift=-0.5cm]{Variable groups}; -->
<!--     % minor modes: tab 4 -->
<!--     \node(tab4_1)[process, below of = tab4, yshift=-0.5cm]{Correlation network}; -->
<!--     \node(tab4_2)[process, below of = tab4_1, yshift=-0.5cm]{Variable groups};     -->
<!-- \end{tikzpicture} -->
<!--     \caption{Workflow of exploratory analysis in the TempNet app} -->
<!--     \label{fig:workflow} -->
<!-- \end{figure} -->

<!-- The mlEDA Shiny App guides user through a series of operations to explore a full dataset. The entire work flow is briefly summarized in Figure \ref{fig:workflow}. Each step corresponds to a tab in the shiny app with funcionalities focusing on certain aspects of the dataset, such as descriptive graphs for univariate distribution and bivariate correlation, multivariate structure and time evolution. All tabs in mlEDA consists of a input panel on the left and an output panel on the right. The former for user inputs, and the later for analytical output following user operation.  -->


<!-- ### Data upload and preview -->

<!-- The first tab of mlEDA allows user to upload a dataset from their own local device. Currently, the dataset is required to be a csv file with long-format, meaning each row is an observation from one subject at a single time point, and repeated measures at different times should be vertically stacked. The uploaded dataset will then be displayed on the output panel, together with a brief summary of sample size and follow-up times.  -->

<!-- It is also important that user should specify the time and subject identifier in this tab, as those are the defining factors of repeated measures over time and will affect future analysis. In some cases a dataset can contain multiple variables for time or subject ID. The IFED dataset, as an example, recorded time both by the week a procedure is scheduled, or the number of days after birth. These variables are often highly correlated as they contains the same piece of information in different forms. Therefore, we recommend user to keep only one of them in the following analysis to avoid redundancy, unless they must be included for specific purposes.  -->

<!-- \begin{figure} -->
<!--     \centering -->
<!--     \includegraphics[width=0.8\linewidth]{AppPics/tab1.png} -->
<!--     \caption{Data upload, preview and speficification} -->
<!--     \label{fig:tab1} -->
<!-- \end{figure} -->

<!-- ### Descriptives -->

<!-- The second tab of mlEDA provides graphs and statistics for detailed exploration of subsets of the data. If offers three aspects of examination: univariate distribution, pairwise relationship and overall structure, implemented in three subtabs respectively. -->

<!-- \paragraph{Univaraiate} -->
<!-- On the first "univariate" subtab, users can choose any single variable from the dataset and examine their distribution at each time point, as will as the change in distribution over time. However, please note that the appropriate methods to visualize these features largely depend on how the "time" variable is distributed. If time grid is relatively sparse (e.g. a handful of time points), users are more likely to think of time as discrete points and focus on each point specifically. On the other hand, a dense grid (e.g. a few hundreds of time points) is more likely to be interpreted as a continuous variable, where the trajectories over time become more important than distribution at each time point. The choice of perceiving time as categorical or continuous depends on the data structure as well as analysis context, and thus is often up to user discretion. Taking the IFED data as example, "week" will be treated as discrete since there are only 12 unique points over the entire dataset. However, infant age coded as days after birth ranges from 0 to 278, with 191 unique values present in between. It should be considered continuous due to this high-density.   -->

<!-- The mlEDA app accomodates this preference by giving user the option to specify time as discrete or continuous, and adjusts the visualization method accordingly. A variable over discrete time will be visualized as a series of boxplots, one at each measurement point (as Figure \ref{fig:tab2.1.1}) Temporal trend is represented by the change in sample median, while the discrepancy across sample is still highlighted at each time point (as Figure \ref{fig:tab2.1.2}).  If the user with the perceive time time as continuous, the app generates a spaghetti plot of individual trajectories, accompanied by as summary trajectory that is smoothed over time. Additional, it provides time-dependent summary of missing pattern across both sample and time. This is often of interest because high-proportion of missing values can severely affect the reliability of correlation measure. User could chose to display a summary table of proportion of missing at each time point, where high-missing will be highlighted. User may wish to remove high-missing variables or time points from down stream analysis to improve robustness. -->

<!-- \begin{figure} -->
<!--     \centering -->

<!--     \begin{subfigure}{0.45\textwidth} -->
<!--     \includegraphics[width=\textwidth]{AppPics/tab2.1.1.png} -->
<!--     \caption{Discrete time}  -->
<!--     \label{fig:tab2.1.1} -->
<!--     \end{subfigure} -->
<!--     \begin{subfigure}{0.45\textwidth} -->
<!--     \includegraphics[width=\textwidth]{AppPics/tab2.1.2.png} -->
<!--     \caption{Continuous time}  -->
<!--     \label{fig:tab2.1.2} -->
<!--     \end{subfigure} -->

<!--     \caption{Descriptives of individual variable distribution and change over time. Figure (a) uses week of scheduled procedure as time. Figure (b) uses infant age as time, coded as days after birth.} -->
<!--     \label{fig:tab2.1} -->
<!-- \end{figure} -->

<!-- \paragraph{Paiwise} -->
<!-- The second subtab examines the time-varying correlation between any pair of variables. User can choose any two variable from the dataset and their preferred correlation measure (pearson or spearman). A plot of correlation trend is then generated on the output panel showing the empirical correlation value at each measurement point. However, please note that the scale of missing is also visualized on the same plot. The points are not only representing the value of correlation coefficient. Their size also indicate how many pairs of observations are used for calculating this correlation. This information is very important because it is relevant to the reliability of correlation. Large point size indicates a large sample, and thus more reliable correlation, and vice versa. In some cases, a pair of variables may have only 2 complete pairs at a single time point, and the correlation measure will always be 1 or -1, which clearly is meaningless. This in fact happened in the IFED dataset, especially when age is considered as time. The 136 participants are spread over 278 days, making sample size at each time point very small. Therefore empirical correlation frequently hits extreme values.  -->

<!-- \begin{figure} -->
<!--     \centering -->

<!--     \begin{subfigure}{0.45\textwidth} -->
<!--     \includegraphics[width=\textwidth]{AppPics/tab2.2.1.png} -->
<!--     \caption{Discrete time}  -->
<!--     \label{fig:tab2.2.1} -->
<!--     \end{subfigure} -->
<!--     \begin{subfigure}{0.45\textwidth} -->
<!--     \includegraphics[width=\textwidth]{AppPics/tab2.2.2.png} -->
<!--     \caption{Continuous time}  -->
<!--     \label{fig:tab2.2.2} -->
<!--     \end{subfigure} -->

<!--     \caption{Descriptives of pairwise correlation and its change over time. Figure (a) uses week of scheduled procedure as discrete time. Figure (b) uses infant age as continuous time, coded as days after birth.} -->
<!--     \label{fig:tab2.2} -->
<!-- \end{figure} -->

<!-- Distribution and/or trajectories of the two variables are displayed together for comparison. The visualization scheme is similar to the previous tab, and thus not displayed in the manuscript for the conciseness. User can also chose to fix the vertical axis range correlation plot between -1 and 1 if they prefer by unchecking the "scale correlation axis to data" box. If user selects less than or more than two variables by mistake, the app will display a warning message.  -->

<!-- \paragraph{Overall} -->

<!-- Tab 3 display the empirical correlation matrix in a heatmap, using different colors for direction and hue for magnitude. User can scroll over the time axis on the input panel to examine its change over time. The structure is simple and straightforward, thus are not displayed in the manuscript for simplicity.  -->

<!-- \begin{figure} -->
<!--     \centering -->
<!--     \includegraphics[width=0.5\linewidth]{AppPics/tab2.3.png} -->
<!--     \caption{Descriptives of the correlation structure of the entire dataset} -->
<!--     \label{fig:tab2-3} -->
<!-- \end{figure} -->


<!-- ### Temporal visualization -->

<!-- This tab hosts the core functionality of the mlEDA app - a dynamic network graph of multivariate correlation and/or association (?DCAN?). We proposed this novel visualization scheme to offer a comprehensive, concise and interpretable representation of the complicated and evolving relationship between multiple measures. The layout reflects the matrix of correlation or association measures on one 2D surface, with nodes indicates variables, and their relative position indicating the strength of relationship. Strongly associated variables are positioned closer to each other while weakly associated variables are positioned further away from each other. By scroll over the time axis on the input panel, user will see the DCAN graph layout adjusts in a visually stable way, using minimal movement to adapt to the data structure at the current time point. The following Section \ref{sec:mds} will explain in detail the how the layout is generated and visual stability is preserved.  -->

<!-- As in Figure \ref{fig:tab3-1}, the correlation matrix is visualized on a 2D surface, where each node indicates a variable. The layout of the variables reflects their relationship, where strongly correlated variables are positioned closer to each other and vice versa. It follows that the change of correlation over time is reflected by the change of layout. For example, when the correlation between two variables increases over time, they will move closer to each other in the network plot. If a group of variables gets increasingly stronger correlated, they will show a clustering trend over time. Section \ref{sec:mds} explains in details the method of layout calculation and dynamic visualization.  -->

<!-- \begin{figure} -->
<!--     \centering -->
<!--     \includegraphics[width=0.8\linewidth]{AppPics/tab3-1.jpg} -->
<!--     \caption{Temporal visualization} -->
<!--     \label{fig:tab3-1} -->
<!-- \end{figure} -->


<!-- The network graph is sufficient to visualize the temporal change of correlation structure. However in practice, the identification of variable groups is often of interest. User may hope to divide the dataset into a few groups of variables, where variables within the same groups have stronger correlation than of different groups. Therefore, TempNet complement the network graph by performing a time-dependent hierarchical clustering on the correlation matrix, and then summarize the group structure in three different plots. The alluvial plot in Figure \ref{fig:tab3-3-3} summarizes change by the group, with each group represented by a color band. Change of group label across time is visualized by a flow of stripe horizontally. The tile plot in Figure \ref{fig:tab3-2-2} summarizes the change of group labels of each variable. Although group assignment is still indicated by color, each row is a variable and it does not change position across the surface. The dendrogram in Figure \ref{fig:tab3-3-3} does not visualize specific group labels, but the hierarchical clustering procedure. It is independent of the user choice of number of groups. The current time point is marked out by a black vertical line on all three graphs. As user move along the time axis in the side panel, the black line will move accordingly along the figure.  -->

<!-- \begin{figure} -->
<!--     \centering -->
<!--     \begin{subfigure}{0.45\linewidth} -->
<!--         \includegraphics[width=\textwidth]{AppPics/tab3-2-1.jpg} -->
<!--         \caption{Alluvial plot} -->
<!--         \label{fig:tab3-2-1} -->
<!--     \end{subfigure} -->
<!--     \begin{subfigure}{0.45\linewidth} -->
<!--         \includegraphics[width=\textwidth]{AppPics/tab3-2-2.jpg} -->
<!--         \caption{Tile plot} -->
<!--         \label{fig:tab3-2-2} -->
<!--     \end{subfigure} -->
<!--     \begin{subfigure}{0.45\linewidth} -->
<!--         \includegraphics[width=\textwidth]{AppPics/tab3-2-3.jpg} -->
<!--         \caption{Dendrogram} -->
<!--         \label{fig:tab3-3-3} -->
<!--     \end{subfigure} -->

<!--     \label{fig:tab3-2} -->
<!-- \end{figure} -->

<!-- In addition to summary graphics, this tab offers more interactive features to accommodate users' needs and preferences. Users can choose to display correlation over certain thresholds. These large correlations are visualized as an edge connecting the corresponding two variables, and the thickness and color hue of the edges reflects the magnitude of the correlation. User can selects a subset of variables to "zoom in" on the network graph. For group summary, user can specify the number of groups, which often needs experimentation to find an optimal value. -->

<!-- ### Integrated visualization -->
<!-- % only variables that shows up in all slices can enter this summart -->
<!-- While the focus of TempNet is to visualize the temporal evolution of data structure, an time-independent overall summary of the entire follow up period can offer useful complementary information from a different perspective. The tab 4 of TempNet app provides such visualization using the same format in tab 3: a network plot with group labels and a dendrogram. The interactive functions are similar to tab 3, except for the time axis, since this figure is not time-dependent and does not change over time. The details regarding figure generation will be provided in Section \ref{sec:mds}. Briefly speaking, the underlying correlation matrix is "pooled" over time into an "integrated" representation, and the same algorithm will be implemented to generated the network graph.   -->

<!-- \begin{figure} -->
<!--     \centering -->
<!--     \includegraphics[width=0.8\linewidth]{AppPics/tab4.jpg} -->
<!--     \caption{Integrated visualization} -->
<!--     \label{fig:tab4} -->
<!-- \end{figure} -->





<!-- # Temporal Network Plot -->
<!-- \label{sec:mds} -->

<!-- In this section, we explain in more details the core functionality of TempNet: the temporal network of correlation. Specifically, we explain how the plot is generated to reflect the correlation structure of the dataset, while also maintain a visual conciseness and stability.  -->

<!-- ## Multidimensional Scaling -->
<!-- % mini-lit review on methods for EDA of temporal data -->
<!-- % existing methods focus on subjects, not variables -->
<!-- % PCA, clustering, .... -->
<!-- As mentioned in Section \ref{sec:intro2}, exploratory analysis methods for multivariate temporal datasets are not well-developed. Existing literature of EDA largely focus on studying the relationship between subjects but not variables. Dimension reduction or clustering, which are arguably the two most widely used EDA methods, both set up the data with raw as subjects and columns as variables[@esl2ed]. However, exploration of correlation is the study of relationship between \textit{variables}. This distinction makes a lot of existing methods inapplicable, even with their longitudinal extensions. However, multidimensional scaling (MDS) has come across as a valid choice in this case, because it is highly flexible with few assumptions on the dataset.  -->

<!-- Essentially, MDS generates variable layout by estimating a set of coordinates that mimics the correlation matrix as much as possible. Specifically, for a dataset $\mathbf{X}$ with P variables $X_1$, ..., $X_P$ at a specific time point, the correlation matrix of this dataset will be a P by P matrix: $Cor(\mathbf{X}) = \{\rho_{lp}\}$, where $\rho_{lp}=Cor(X_l, X_p)$. The correlation $\rho_{lp}$ is a bounded value between -1 and 1 indicating the strength of "association". It reflects how $X_l$ and $X_p$ moves concordantly or discordantly with each other, and thus can also be interpreted as "similarity". Therefore, the correlation matrix can be easily transformed into a "dissimilarity" matrix: $\mathbf{\Delta} = {\delta_{lp}}$, where $\delta_{lp} = 1-|\rho_{lp}|$. This dissimilarity matrix $\mathbf{\Delta}$ is used as a high-dimensional representation of correlation.  -->

<!-- When the dataset is projecting onto a 2D surface, and the representation now is a P by 2 matrix $\mathbf{C}$. A variable $X_p$ is represented by two coordinates $(c_{p1}, c_{p2})$ indicating horizontal and vertical positions respectively. We can then calculate the Euclidean distance between any pair of variables: $d_{lp} = \sqrt{(c_{l1}-c_{p1})^2+(c_{l2}-c_{p2})^2}$. The matrix of pairwise Euclidean distance is a P by P matrix: $\mathbf{D}= \{d_{lp}\}$. This will be the low-dimensional representation of the correlation matrix.  -->

<!-- The goal is to find a low-dimensional representation that stays true to the high-dimensional representation. Therefore, we would like to minimize the difference between $\mathbf{\Delta}$ and $\mathbf{D}$. This leads to the stress loss function[@kruskal1964]:  -->

<!-- \begin{align} -->
<!--     Stress(\mathbf{C}) = \frac{||\mathbf{\Delta} - \mathbf{D}||^2}{||\mathbf{\Delta}||^2}. -->
<!--     \label{eq:stress} -->
<!-- \end{align} -->

<!-- By minimizing the stress loss \ref{eq:stress}, we will be able to get the 2D coordinates that is most reflective of the correlation structure.  -->

<!-- ## Temporal stability -->

<!-- Note that the MDS algorithm alone does not consider time changes.Dynamic extension is needed to accommodate the temporal component of the dataset. If we consider the evolution process of data structure as a "movie", then a correlation network plot generated by MDS at a specific time point would be a "slice" or "screenshot". However, it is not ideal to simply regenerate a separate plot at each time point. Regeneration will induce random initialization of vertices positions. When implemented repeatedly over time, this causes variable nodes to bounce around the surface, which is not friendly to users examination and comprehension. To stabilize the network plot, we need to minimizing the change of layout between slices, which may translate to adding a penalization of changes into the layout computation. Below We introduce two methods that achieve this purpose: Dynamic MDS vs Splines MDS. The major difference between these two methods is how they perceive the time variable. While Dynamic MDS treats time as discrete points, Splines MDS treats time as the observations of a continuous variable.  -->

<!-- % define and discuss "measurement grid" -->

<!-- \paragraph{Dynamic MDS} -->


<!-- When time is a series of discrete "slices", it follows the consistency of visualization can be how similar the layouts between adjacent slices are. Dynamic MDS follows such logic and impose penalization on the difference between adjacent slices to ensure stability. The loss function in this case is penalized stress:  -->

<!-- \begin{align} -->
<!--  Loss(\mathbf{C}) = \sum_{t}\frac{||\mathbf{\Delta}_t - \mathbf{D}_t||^2}{||\mathbf{\Delta}_t||^2}+ -->
<!--  \lambda ||\mathbf{C}_t-\mathbf{C}_{t-1}||^2. -->
<!--     \label{eq:dMDSloss}    -->
<!-- \end{align} -->

<!-- This method works well on datasets with small to moderate dimension. As an example, the motivational data set has 136 subjects, 32 variables and 12 unique measurement times, and it takes about 2 minutes to generate a complete graph. However, the computation time increases exponentially with measurement grid density and quickly becomes unfeasible. Our simulation shows a dataset with 100 unique repeated measures can take up to 2.5 hours to generate a compete graph. -->

<!-- In addition to computational burden, this method also works poorly with the presence of missing values, or when the measurement grids are different across variables. Both are very common in practice, as variables are collected from different procedures. For example, in the IFED datasets, growth measures are taken consistently at all visits, but ultrasound are only measured every other visit. Hormones, while collected every visit, are only taken on part of the sample. Dynamic MDS algorithm, when implemented on such datasets, often fail to generate stable visualization. This is because missing values cannot contribute to the penalization and thus cannot influence the generated layout. As a result, variables with large proportions of missing tend to bounce around the surface in a random manner.  -->

<!-- The dynamic MDS also introduce another source of potential instability-when the measurement grid is irregular, we would also see entry and exit of nodes in the plot as time changes. At a specific time point, the positions of unmeasured variables cannot be computed, since their correlation with other  variables cannot be computed.  -->

<!-- \paragraph{Splines MDS} -->

<!-- Recall in Section \ref{sec:appfunc}, we mentioned time can be perceived either as discrete points, or realizations of a continuous process. In fact, when the measurement grid is dense, i.e. large number of repeated measures are taken with small intervals in between, it is often more efficient to consider the measurement as discrete realizations of a continuous latent process. Following these assumptions, we also model the layout of the correlation network graph as continuous processes, and enhance stability by penalize the "smoothness" of layout over time. -->

<!-- As the previous section, the layout of the network graphed is mathematically expressed by the coordinates of vertices. We can model them as smooth functions over time using spline basis functions:  -->

<!-- \begin{align} -->
<!-- \mathbf{c}_p(t) &= (c_{p1}(t), c_{p2}(t)) \label{eq:smooth_coord} \\ -->
<!-- c_{p1}(t) &= \sum_{k=1}^K \xi_{pk}\phi_k(t) = \mathbf{\xi}_p \mathbf{\Phi}(t) \nonumber \\ -->
<!-- c_{p2}(t) &= \sum_{k=1}^K \zeta_{pk} \phi_k(t) = \mathbf{\zeta}_p \mathbf{\Phi}(t) \nonumber.  -->
<!-- \end{align} -->

<!-- The position of the vertex indicating variable $X_p$ will then change smoothly with t, determined by parameters $\mathbf{\xi}_p$ and $\mathbf{\zeta}_p$. It follows that the lower dimensional representation $\mathbf{D}$ will be a collection of the smooth coordinates in \eqref{eq:smooth_coord}: $\mathbf{D}(t, \mathbf{\xi}, \mathbf{\zeta}) = \{\mathbf{c}_p(t), p = 1...P\}$. And the stress function can be written as $Stress(\mathbf{C}(t, \mathbf{\xi}, \mathbf{\zeta})) = \frac{||\mathbf{\Delta}_t - \mathbf{D}(t)||^2}{||\mathbf{\Delta}_t||^2}$.  -->

<!-- Since the coordinates are constructed using spline basis functions, it is possible to improve temporal stability by adding smoothness penalization. For example, we can add a second derivative penalization: -->

<!-- \begin{align} -->
<!--     Loss(\mathbf{\xi}, \mathbf{\zeta}) = \int_t Stress(\mathbf{C}(t, \mathbf{\xi}, \mathbf{\zeta})) + \sum_{p=1}^P\lambda(\mathbf{\xi}_p+\mathbf{\zeta}_p)\mathbf{\Phi}'' -->
<!--     \label{eq:SPLloss} -->
<!-- \end{align} -->

<!-- From the Spline MDS loss function in \eqref{eq:SPLloss}, we can see this approach has an advantage over the Dynamic MDS approach when measurement grid is different across variables. Specifically, the layout of network computed here is determined by spline basis coefficients $\mathbf{\xi}_p, \mathbf{\zeta}_p$, which are time-independent. Although variables could be unmeasured at certain times, their layout could still be computed in a consistent manner. In addition, this loss function can also be factored by time, which makes parallelization easier and thus improves efficiency.   -->

<!-- % ## Simulation -->

<!-- % In this section, we implemented Dynamic and Splines MDS on simulated datasets with known correlation structure and examine the network plots they generated. By comparing the visualization to the real time-dependent correlation structure, we assess if the network plots can both intuitively and accurately reflect the true data structure. We demonstrate its advantages to facilitate interpretation and provide additional insight compared to existing visualization tools. We would also like to compare Dynamic MDS to Splines MDS on different structure, identify their pros and cons and accordingly advice practical use.   -->

<!-- % ### Data generation -->

<!-- % In this scenario we aim to explore a realistic situation where multiple measures are repeatedly collected by multiple procedures during the follow-up time at a low frequency. Typically, the unique number of measurement points in the dataset should be small enough for time to be considered discrete. Many clinical trials and public health studies fall into this scenario, including our motivational data set (IFED) with up to 12 visits during the entire study duration.  -->

<!-- % It is also reasonable to expect the measures collected follow certain group structure, such that a set of variables may be more strongly correlated within themselves than the others. Both the within- and between- group correlation can also change over time. For example, in the IFED study, we expect the growth measures (height, weight, BMI) to be closely intercorrelated, while the hormones and reproductive organ volumes may be closely intercorrelated. At the same time, the correlation between growth and hormones/reproductive organs could be weaker. -->

<!-- % Out simulation mechanism is designed to imitate real datasets based on the realistic expectations above. Let $t$ be an indicator of the discrete time points and the total number measurement times in the dataset is $T$. We observed $P$ variables from $G$ different groups. The variable $p$ from group $g$ is denoted as $X_{gp}$, $g=1...G$ and $p=1...P$. Then the data is generated from the model below: -->

<!-- % \begin{equation} -->
<!-- %   X_{gpt}= f_{gpt}+a_{gt}+b_{gpt}+\epsilon_{gpt}.  -->
<!-- %   \label{eq:gendata1} -->
<!-- % \end{equation} -->

<!-- % This model assumes that each variable can be decomposed into three components: a fixed-effect $f$, random effects $a$ and $b$, and random noise $\epsilon$. The random effect also consists of two levels: a group level $a$ and a group-variable level $b$. We further assume that group the level random effect and group-variable random effect are generated independently from centered multivariate normal distribution: $\mathbf{a}_t =(a_{1t}...a_{Gt}) \sim N(\mathbf{0}, \mathbf{\Sigma}_{at})$, $\mathbf{b}_t =(b_{11t}...b_{GPt}) \sim N(\mathbf{0}, \mathbf{\Sigma}_{bt})$. Here $\mathbf{\Sigma}_{at}$ and $\mathbf{\Sigma}_{bt}$ are time-dependent covariance matrices with dimension $G$ and $P$ respectively. If group $g$ has $P_g$ variables and $\mathbf{b}_{gt} = (b_{g1t}...b_{gP_gt})$ , then $Cov(\mathbf{b}_{gt})=\mathbf{\Sigma}_{bgt}$ is the gth diagonal block of $\mathbf{\Sigma}_{bt}$. The random noise $\epsilon_{gpt}$ independently follow $N(0, \sigma^2)$. Although this data generation model is very similar to the linear mixed model framework, caution that the same variables at different time points are not assumed to be collected from the same subject.  -->

<!-- % It follows that the within- and between-group correlation is determined by the random effect covariance matrices:  -->

<!-- % \[\begin{aligned} -->
<!-- %    \text{Within-group: } & Cov(\mathbf{X}_{gt}) = Var(a_{gt}) + Cov(\mathbf{b}_{gt}) = Var(a_{gt}) + \mathbf{\Sigma}_{bgt} \\  -->
<!-- %     \text{Between-group: } & Cov(\mathbf{X}_{gt}, \mathbf{X}_{g't}) = Cov(a_{gt}, a_{g't}) + Cov(\mathbf{b}_{gt}, \mathbf{b}_{g't}), -->
<!-- % \end{aligned}\]   -->

<!-- % Where $Var(a_{gt})$ is the gth diagonal element of $\mathbf{\Sigma}_{at}$, and $Cov(a_{gt}, a_{g't})$ is the $(g, g')$ element of $\mathbf{\Sigma}_{at}$. -->

<!-- % The results presented below are produced on datasets with 15 variables ($P=15$) from three different groups ($G=3$). The group level random effects are generated from a time-independent covariance matrix, with diagonal elements of 1 and off-diagonal elements of 0.45. Each of the groups have five variables ($Pg = 5, g = 1, 2, 3$). The group-variable level random effect is generated from the following covariance matrices:  -->

<!-- % \[\begin{aligned} -->
<!-- % \{\mathbf{\Sigma}_{b1t}\}{ij} &= 1I(i=j) + 0.45I(i \neq j)\\ -->
<!-- % \{\mathbf{\Sigma}_{b2t}\}{ij} &= 1I(i=j) + \frac{0.9t}{T} I(i \neq j)\\ -->
<!-- % \{\mathbf{\Sigma}_{b3t}\}{ij} &= 1I(i=j) + (1-\frac{0.9t}{T})I(i \neq j), -->
<!-- % \end{aligned}\] -->

<!-- % so that group 1 has constant covariance, group 2 has increasing covariance and group 3 has decreasing covariance.  -->

<!-- % The total number of measurement points is varied across simulations to examine the effect of measurement grid density. The number of subjects at each measurement time point is fixed at 100 ($N_t$ = 100). -->


<!-- % ### Measurement grid density -->
<!-- % % add figure on same data but complete -->
<!-- % A major difference between Dynamic and Splines MDS is their performance at different measurement grid density. Here we define measurement grid density as the number of unique measurement time points in the dataset. For example, in the IFED study data set, there are 12 unique measurement points when we use week as the time variable, which is a relatively sparse grid. However, the user may wish to use participant age as the time indicator instead, which is measured by days from birth. Then the unique measurement points will be 191, which is a denser grid.  -->

<!-- % Our simulations has revealed that Dynamic MDS may have better visualization results and higher efficiency on a low-density grid, while Splines MDS performs better and more efficiently on a denser grid. Figure \ref{fig:sim_temp} compares the visualization outcome between Dynamic and Spliens MDS when there are only 10 measurements across follow-up period, which is a low-density grid. Both Splines and Dynamic MDS are able to reflect the correlation structure of the simulated data and its temporal change. Across all time points, the nodes representing variable from the same group (indicated by color) are consistently positioned close together. The green nodes from group 1 are positioned evenly and their relative positions stay similar through out all time points. reflecting the constant within-group correlation. The orange nodes from group 2 gradually move closer, reflecting its increasing within-group correlation. The purple nodes from group 3 gradually move further away from each other, reflecting its decreasing within group correlation. While both methods generated visualization consistent with the true correlation change, Splines MDS appear slightly more unstable as the group positions rotate more than Dynamic MDS. This is a natural outcome considering the essence of Splines basis functions. The pattern of position change also potentially depends on the arbitrary choices of basis functions, including type, degree and dimension. -->

<!-- % Figure \ref{fig:time1} compares the time spent generation network correlation graph by Dynamic and Splines MDS. It reveals that when the dataset includes less than 50 measurement points, Dynamic MDS has a slight advantage in computation time over Splines MDS. As the measurement grid density increases, the difference is soon reversed. In fact, Dynamic MDS soon becomes infeasible at high density and the only practical choice is Splines MDS. Please note that this difference also depends on arbitrary choices regarding Splines basis models, such as the type of Splines functions and degrees of freedom. The current result is generated with 20 quadratic m-Spline basis functions. Generally speaking, the computation time increases with the complexity of Splines basis set-up. A comprehensive investigation of its effect is beyond the scope of this manuscript.  -->

<!-- % \begin{figure} -->
<!-- %     \centering -->
<!-- %     \includegraphics[width=0.5\linewidth]{TempSimPics/Sim1Time.jpeg} -->
<!-- %     \caption{Computation time to generate a temporal network plot of correlation. } -->
<!-- %     \label{fig:time1} -->
<!-- % \end{figure} -->



<!-- % \begin{figure} -->
<!-- % \begin{subfigure}{0.3\textwidth}  -->
<!-- %         \includegraphics[width=\textwidth]{TempSimPics/DynMDS_t1.jpeg} -->
<!-- % \end{subfigure} -->
<!-- % \begin{subfigure}{0.3\textwidth}  -->
<!-- %         \includegraphics[width=\textwidth]{TempSimPics/DynMDS_t5.jpeg} -->
<!-- % \end{subfigure} -->
<!-- % \begin{subfigure}{0.3\textwidth}  -->
<!-- %         \includegraphics[width=\textwidth]{TempSimPics/DynMDS_t10.jpeg} -->
<!-- % \end{subfigure} -->

<!-- % \begin{subfigure}{0.3\textwidth}  -->
<!-- %         \includegraphics[width=\textwidth]{TempSimPics/SplMDS_t1.jpeg} -->
<!-- % \end{subfigure} -->
<!-- % \begin{subfigure}{0.3\textwidth}  -->
<!-- %         \includegraphics[width=\textwidth]{TempSimPics/SplMDS_t5.jpeg} -->
<!-- % \end{subfigure} -->
<!-- % \begin{subfigure}{0.3\textwidth}  -->
<!-- %         \includegraphics[width=\textwidth]{TempSimPics/SplMDS_t10.jpeg} -->
<!-- % \end{subfigure} -->
<!-- %     \caption{Temporal network visualization of Dynamic and Splines multidimensional scaling methods at low measurement density with 10 measurement points. The color of nodes represent groups of variables with within-group correlation structure.} -->
<!-- %     \label{fig:sim_temp} -->
<!-- % \end{figure} -->

<!-- % ### Measurement grid irregularity -->

<!-- % Another important factor of visualization performance is the regularity of the measurement grid of different variables in the dataset. Different measures are often not collected at the same time points in practical settings, which can cause difficult in analysis. For example, while the physical measures are consistently collected at every scheduled visits, ultrasounds are only implemented every other visit for the majority of the variables. The specimen collection is done every visit, but only on a subset of the sample, and the subset also changes at each visit.  -->


<!-- % Below we present the comparison between Dynamic and Splines MDS on a simulated dataset with the presence of measurement grid irregularity. We assume variables in the first group (green nodes) are collected at only half of the follow up time points. In other words, these variables are completely missing 50\% of the time. The experiments review that the quality of visualization is very context-dependent. First, we could see Dynamic MDS is not able to visualize Unmeasured at each time point. From Formula \ref{eq:dMDSloss}, if a variable is not measured at a time point, its dissimilarity with any other variables cannot be calculated, and its coordinates cannot be generated as well. Consequently, these irregularly measured variables will disappear and reappear from the graph repeatedly with changing positions, just as the green nodes in the top row of Figure \ref{fig:sim_miss}. They only showed up at t = 0.96 among the three selected time points. Moreover, since all the nodes are projected and scaled down onto the same surface area, entry and exit of nodes can cause the other nodes to expand from or shrink close to each other. This can cause dramatic changes to the layout. For example, in Figure \ref{fig:sim_miss} we can see group 2 (orange nodes) rotate across the plot surface. These changes could cause visual instability and as a result difficult in reading.  -->

<!-- % On the other hand Splines MDS is built on a set of known functions over time and time-dependent coefficient, thus can compute the position of missing nodes representing unmeasured variables as long as the variables are not missing during the entire follow up time. However, this does not necessarily mean Splines MDS always has more stable visualization than Dynamic MDS. While Spline MDS is able to consistently visualize all variables in the dataset, the computed position of missing variables can depend on may factors, including the data scale, the distribution of missing measurements over time, and arbitrary setup of the spline basis functions. As the bottom row of Figure \ref{fig:sim_miss} shows, variables from group 1 are missing at both time = 0 and time = 0.5 (denoted by circles), but the "guessed" positions is much better at 0.5. There is because at the start of follow up time, we have not yet observed anything to base the computation on, causing the nodes to be placed at random on the surface. At midpoint, the layout is computed based on observations so far, and thus reflects the true underlying structure more accurately. Through repeated experiments, we observed that computation on denser measurement grids is generally better than sparser grids. Computation also tend to be worse over consecutive missing points, even with the same grid density and proportion of missing. The reason behind these observations is straightforward-we do not have enough points along the spline basis functions to recover the true underlying structure.  -->

<!-- % \begin{figure} -->
<!-- % \begin{subfigure}{0.3\textwidth} -->
<!-- % \includegraphics[width=\textwidth]{MissSimPics/DynMDS_miss2_t1.jpeg} -->
<!-- % \end{subfigure} -->
<!-- % \begin{subfigure}{0.3\textwidth} -->
<!-- % \includegraphics[width=\textwidth]{MissSimPics/DynMDS_miss2_t101.jpeg} -->
<!-- % \end{subfigure} -->
<!-- % \begin{subfigure}{0.3\textwidth} -->
<!-- % \includegraphics[width=\textwidth]{MissSimPics/DynMDS_miss2_t192.jpeg} -->
<!-- % \end{subfigure} -->

<!-- % \begin{subfigure}{0.3\textwidth} -->
<!-- %     \includegraphics[width=\textwidth]{MissSimPics/SplMDS_miss2_t1.jpeg} -->
<!-- % \end{subfigure} -->
<!-- % \begin{subfigure}{0.3\textwidth} -->
<!-- %     \includegraphics[width=\textwidth]{MissSimPics/SplMDS_miss2_t101.jpeg} -->
<!-- % \end{subfigure} -->
<!-- % \begin{subfigure}{0.3\textwidth} -->
<!-- %     \includegraphics[width=\textwidth]{MissSimPics/SplMDS_miss2_t192.jpeg} -->
<!-- % \end{subfigure} -->
<!-- %     \caption{Temporal network visualization of Dynamic and Splines multidimensional scaling methods at medium measurement density with 200 measurement points with the presence of irregular grid. The color of nodes represent groups of variables with within-group correlation structure. Variables in the green group is unobserved at half of the measurement grids. Specific time points of missing are randomly selected.} -->
<!-- %     \label{fig:sim_miss} -->
<!-- % \end{figure} -->



<!-- % \textcolor{red}{Update results when the server is back up. Network plots when grid is irregular and density is medium-high.} -->



<!-- % % properties of cross-covariance matrix -->


<!-- % % For simplicity, we assume the distribution of sensor data follows a classical framework in functional data analysis:  -->

<!-- % %  $$X_{pg}(t) = f_0(t)+\sum_{k=1}^K\xi_{pgk}\phi_k(t)+\sum_{l=1}^L\zeta_{gl}\psi_l(t)+\epsilon_p(t)$$ -->

<!-- % % or rather:   -->
<!-- % % \[\begin{aligned} -->
<!-- % % \mathbf{X}_{pg}  = \mathbf{f}_0+\mathbf{\Phi} \mathbf{\xi}_{pg} \mathbf{\Phi}^T+\mathbf{\Psi} \mathbf{\zeta}_{g} \mathbf{\Psi}^T+\mathbf{\epsilon}_{pg}\\ -->
<!-- % % % \mathbf{\xi}_{pg} & \sim N(\mathbf{0}, \mathbf{\Lambda})\\ -->
<!-- % % % \mathbf{\zeta}_{g} & \sim N(\mathbf{0}, \mathbf{\Gamma}) -->
<!-- % % \end{aligned}\] -->



<!-- % % where $p = 1...P$ index variable and $g=1...G$ index the group variables belong to.  -->

<!-- % % Random effects on both variable-group level and group-level are linear combination of a set of basis functions. Randomness is introduced through coefficients $\xi_{pgk}$ and $\zeta_{gl}$, including potential between-group and within-group correlation. In fact, we could derive from the model set up: -->

<!-- % % \begin{align} -->
<!-- % %     \text{Within-group}: Cov(\mathbf{X}_{pg},\mathbf{X}_{p'g}) & = \mathbf{\Phi} Cov(\mathbf{\xi}_{pg}, \mathbf{\xi}_{p'g}) \mathbf{\Phi}^T+ \mathbf{\Psi} Cov(\mathbf{\zeta}_{g}, \mathbf{\zeta}_{g}) \mathbf{\Psi}^T \\ -->
<!-- % %     \text{Between-group}: Cov(\mathbf{X}_{pg},\mathbf{X}_{p'g'}) & = \mathbf{\Phi} Cov(\mathbf{\xi}_{pg}, \mathbf{\xi}_{p'g'}) \mathbf{\Phi}^T+ \mathbf{\Psi} Cov(\mathbf{\zeta}_{g}, \mathbf{\zeta}_{g'}) \mathbf{\Psi}^T -->
<!-- % % \end{align} -->

<!-- % % If we assume $\mathbf{\xi}_{pg} \sim N(\mathbf{0}, \mathbf{\Lambda})$ and is identical and independence across p and g, the within- and between- group correlation will entirely depend on the distribution of group-level coefficients. If the off diagonoal blocks are zero matrices, i.e. cross-covariance between $\mathbf{\zeta_g}$ and $\mathbf{\zeta_g'}$ is zero, then group-level coefficients are independently generated for each group. Consequently, there will be no between-group covariance. -->



<!-- % % Assume they are mutual independent, this framework introduces within-group correlation but not between group correlation. That is, $Cov(X_{p_1g_1}, X_{p_2g_2}) = \sum_{l=1}^L \psi_l(t)^2$ and $Cov(X_{p_1g}, X_{p_2g}) = 0$ -->

<!-- % % For further simplicity, we also assume coefficients are mutually independent within each level:  -->

<!-- % % \[\begin{aligned} -->
<!-- % % \text{Variable-group level: } & \mathbf{\Phi} = \{\sqrt{2}sin(2\pi t), \sqrt2 cos(2\pi t), \sqrt2 sin (4\pi t), \sqrt2 cos(4\pi t)\}, \\ -->
<!-- % % \text{Subject-series level: } & \mathbf{\Psi} = \{\sqrt{2}sin(6\pi t), \sqrt2 cos(6\pi t), \sqrt2 sin (8\pi t), \sqrt2 cos(8\pi t)\},\\ -->
<!-- % %                              & \mathbf{\xi}, \mathbf{\zeta} \sim N(\mathbf{0}, \mathbf{I}),\ \epsilon_p(t) \sim N(0, 1) \\ -->
<!-- % % \end{aligned}\] -->



<!-- % # Case studies -->
<!-- % \label{sec:case} -->

<!-- % In this section, we apply TempNet on our motivational dataset and demonstrate its use in a practical setting. Recall in IFED study, visits are scheduled by weeks after birt, and the age of infants are also collected at each visit as days from birth. This provides as with two potential time grids to use: we can use weeks from birth, which is a sparse measurement grid with 12 unique points with uneven intervals from 0 to 36. Alternatively, it could be of interest to use age in days as time, which is a much denser but also uneven grid with 191 unique values range from 0 to 278. While the former is better considered discrete, the latter should be considered as a continuous. In fact, the week measure is equivalent to  binned age, since a certain number weeks after birth will cover a range of days after birth.  -->

<!-- % ## Analysis by week -->

<!-- % Here as visit week is treated as a discrete variable, Dynamic Multidimensional Scaling is used to generate the temporal network graph. -->




<!-- % ## Analysis by age -->

<!-- % Days after birth is treated as a discrete variable, therefore the network graph generated based on this measure will use Splines Multidimensional Scaling -->

<!-- % # Discussion -->

<!-- % other factors affecting visualization: measure type, sample size, etc.  -->

<!-- % \begin{itemize} -->
<!-- %     \item To the authors knowledge, -->
<!-- % this is the first open source R package/app to facilitate temporal MDS and dynamic network visualization based on it (list existing tools) -->
<!-- % \end{itemize} -->

<!-- % computation efficiency: server, separate upload of coordinates, dynamds and splmds -->

<!-- % measures of association beyond correlation e.g. mutual information, entropy -->

<!-- % app functions: other files, etc.  -->



\printbibliography

